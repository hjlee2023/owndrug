# collector_gn.py
import feedparser
import sqlite3
from datetime import datetime

from dateutil import parser  # ë§¨ ìœ„ import ìª½ì— ì¶”ê°€

CLINICAL_KEYWORDS = [
    "phase 1", "phase i",
    "phase 2", "phase ii",
    "phase 3", "phase iii",
    "clinical trial", "clinical study",
    "topline", "top-line",
    "pivotal", "registrational",
    "interim results", "final results",
    "fda", "nda", "bla", "ema",
    "approval", "approves", "authorized", "authorization"
]

# globalnewswire ë°”ì´ì˜¤í…Œí¬ RSS
RSS_URL = "https://www.globenewswire.com/RssFeed/industry/4577-Pharmaceuticals/feedTitle/GlobeNewswire%20-%20Industry%20News%20on%20Pharmaceuticals"


def collect_news():
    print("\n" + "="*70)
    print("ğŸ“° globalnewswire ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print("="*70 + "\n")

    # RSS íŒŒì‹±
    print(f"ğŸ”— RSS: {RSS_URL}")
    feed = feedparser.parse(RSS_URL)

    if not feed.entries:
        print("âŒ RSSì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“¦ feedparser ì„¤ì¹˜ í™•ì¸: pip install feedparser")
        return

    print(f"âœ… RSSì—ì„œ {len(feed.entries)}ê°œ í•­ëª© ë°œê²¬\n")

    conn = sqlite3.connect('fda_news.db')
    cursor = conn.cursor()

    new_count = 0
    skip_count = 0

    for entry in feed.entries:
        title = entry.title
        link = entry.link
        pub_date = entry.get('published', '')
        summary = entry.get('summary', entry.get('description', ''))[:500]
        guid = entry.get('id', link)

        text = f"{title} {summary}".lower()
        if not any(k in text for k in CLINICAL_KEYWORDS):
            skip_count += 1
            continue

        # ì¤‘ë³µ ì²´í¬ (link ê¸°ì¤€) - FDA/ë‹¤ë¥¸ ì†ŒìŠ¤ì™€ë„ ê³µí†µìœ¼ë¡œ ë§‰í˜
        cursor.execute("SELECT id FROM news WHERE link = ?", (link,))
        if cursor.fetchone():
            skip_count += 1
            continue

        # ë‚ ì§œ íŒŒì‹±
        try:
            if pub_date:
                # dateutilë¡œ ê°•ë ¥í•œ íŒŒì‹±
                from dateutil import parser
                try:
                    dt = parser.parse(pub_date)
                    pub_date_str = dt.strftime('%Y-%m-%d %H:%M:%S')
                except Exception:
                    # fallback: í˜„ì¬ ì‹œê°„
                    pub_date_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            else:
                pub_date_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        except Exception:
            pub_date_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {pub_date}")

        # DB ì €ì¥ (source='globe')
        try:
            cursor.execute("""
INSERT INTO news (guid, title, link, pub_date, summary, analyzed, source)
VALUES (?, ?, ?, ?, ?, 0, 'globe')
""", (guid, title, link, pub_date_str, summary))

            print(f"âœ… [globe] [{pub_date_str}] {title[:70]}...")
            new_count += 1
        except sqlite3.IntegrityError:
            # UNIQUE ì œì•½ ìœ„ë°˜ (guid/guid+link ì¤‘ë³µ)
            skip_count += 1
            continue
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            continue

    conn.commit()
    conn.close()

    print("\n" + "="*70)
    print(f"ğŸ‰ GlobeNewswire(Biotech) ìˆ˜ì§‘ ì™„ë£Œ: ì‹ ê·œ {new_count}ê±´ | ì¤‘ë³µ {skip_count}ê±´")
    print("="*70 + "\n")

    if new_count == 0 and skip_count == 0:
        print("âš ï¸ ì•„ë¬´ê²ƒë„ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("RSS ì£¼ì†Œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    collect_news()
